{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import requests \n",
    "import pandas as pd\n",
    "import os \n",
    "import time\n",
    "\n",
    "def wikiscraper(team_name, year_int):\n",
    "    # team ex: \"Illinois_Fighting_Illini\"\n",
    "    # year_int ex: 2024\n",
    "    team = team_name.replace(\" \", \"_\")\n",
    "    year = str(year_int-1) + \"-\" + str(year_int%2000)\n",
    "    csv_folder = \"csv_files\"\n",
    "    year_path = os.path.join(csv_folder, year)\n",
    "    csv_file_path = os.path.join(year_path, f'{team}_{year}.csv')\n",
    "\n",
    "    if os.path.exists(csv_file_path):\n",
    "        return\n",
    "    try: \n",
    "        roster = f\"https://en.wikipedia.org/wiki/{year}_{team}_men%27s_basketball_team\"\n",
    "        result = requests.get(roster)\n",
    "        if(result.status_code == 404):\n",
    "            print(team_name + \" error 404 \" + year)\n",
    "            return\n",
    "        content = result.text\n",
    "\n",
    "        soup = BeautifulSoup(content, 'lxml')\n",
    "        table = soup.find('table', class_= 'toccolours')\n",
    "        table = table.find('table', class_='sortable')\n",
    "\n",
    "        player_data = []\n",
    "\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows[1:]:\n",
    "            cells = row.find_all('td')\n",
    "            name = cells[2].text.strip().replace('\\xa0(W)', '')\n",
    "            hometown = cells[7].text.strip()\n",
    "            player_data.append({'Team': team_name, 'Year': year_int, 'Name': name, 'Hometown': hometown})\n",
    "    except:\n",
    "        print(\"error thrown for \" + team_name + \" \" + year)\n",
    "        return\n",
    "    df = pd.DataFrame(player_data)\n",
    "\n",
    "    if not os.path.exists(csv_folder):\n",
    "        os.makedirs(csv_folder)\n",
    "\n",
    "    if not os.path.exists(year_path):\n",
    "        os.makedirs(year_path)\n",
    "\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "    print(f'{team_name} CSV uploaded!')\n",
    "    time.sleep(4)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penn State Nittany Lions error 404 2022-23\n",
      "Penn State Nittany Lions error 404 2021-22\n",
      "Penn State Nittany Lions error 404 2020-21\n",
      "error thrown for Iowa Hawkeyes 2023-24\n",
      "error thrown for Michigan Wolverines 2019-20\n",
      "error thrown for Michigan Wolverines 2018-19\n",
      "error thrown for Michigan Wolverines 2017-18\n"
     ]
    }
   ],
   "source": [
    "bigten = {\"Penn State Nittany Lions\", \"Iowa Hawkeyes\", \"Illinois Fighting Illini\", \"Ohio State Buckeyes\", \"Wisconsin Badgers\", \"Purdue Boilermakers\", \"Indiana Hoosiers\", \"Michigan Wolverines\", \"Michigan State Spartans\", \"Nebraska Cornhuskers\", \"Northwestern Wildcats\", \"Minnesota Golden Gophers\",  \"Maryland Terrapins\", \"Rutgers Scarlet Knights\"}\n",
    "# Ones that didnt work altogether \n",
    "for team in bigten:\n",
    "    #print(\"uploading \" + team)\n",
    "    for year in range (2024,2016,-1):\n",
    "        wikiscraper(team, year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
